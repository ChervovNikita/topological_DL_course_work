{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rips(maxdim=1, thresh=inf, coeff=2, do_cocycles=False, n_perm = None, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ripser import lower_star_img\n",
    "from ripser import Rips\n",
    "vr = Rips()\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "\n",
    "import persim\n",
    "import diagram2vec\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "from gtda.diagrams import PersistenceEntropy, PersistenceImage, BettiCurve\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 300\n",
    "sigma1 = 4\n",
    "sigma2 = 2\n",
    "t = 0.01\n",
    "\n",
    "def generate(N, S, W=300, sigma1=4, sigma2=2, t=0.01, bins=64):\n",
    "\n",
    "    z = np.zeros((N, S, 2))\n",
    "    for n in range(N):\n",
    "        z[n, 0] = np.random.uniform(0, W, size=(2))\n",
    "        for s in range(S-1):\n",
    "            d_1 = np.random.normal(0, sigma1)\n",
    "            d_2 = np.random.normal(0, sigma1)\n",
    "            z[n, s+1, 0] = (z[n, s, 0] + d_1) % W\n",
    "            z[n, s+1, 1] = (z[n, s, 1] + d_2) % W\n",
    "\n",
    "    z_r = z.reshape(N*S, 2)\n",
    "    H, _, _ = np.histogram2d(z_r[:,0], z_r[:,1], bins=bins)\n",
    "    \n",
    "    G = gaussian_filter(H, sigma2)\n",
    "    G[G < t] = 0\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [02:45<00:00, 301.53it/s]\n",
      "100%|██████████| 50000/50000 [02:23<00:00, 348.96it/s]\n"
     ]
    }
   ],
   "source": [
    "count = 50000\n",
    "classes_count = 2\n",
    "\n",
    "images = np.zeros((classes_count * count, 64, 64))\n",
    "\n",
    "# class A\n",
    "N = 100\n",
    "S = 30\n",
    "\n",
    "for n in tqdm(range(count)):\n",
    "    images[n] = generate(N, S)\n",
    "    \n",
    "# class B\n",
    "N = 250\n",
    "S = 10\n",
    "\n",
    "for n in tqdm(range(count)):\n",
    "    images[n+count] = generate(N, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PorusDataset(Dataset):\n",
    "    def __init__(self, diagrams, labels):\n",
    "        self.diagrams = diagrams\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.diagrams)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.diagrams[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "# cedt\n",
    "# cedt x ...\n",
    "# conv\n",
    "# multiconv\n",
    "# dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POT (Python Optimal Transport) package is not installed. Try to run $ conda install -c conda-forge pot ; or $ pip install POT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import gudhi as gd\n",
    "from gudhi.wasserstein import wasserstein_distance\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "from ripser import lower_star_img\n",
    "from ripser import Rips\n",
    "\n",
    "import persim\n",
    "import diagram2vec\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import gudhi as gd\n",
    "from gudhi.wasserstein import wasserstein_distance as dist_w\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from scipy.ndimage import maximum_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagram(image, device, sublevel=True):\n",
    "    # get height and square image\n",
    "    h = int(np.sqrt(image.shape[0]))\n",
    "    image_sq = image.reshape((h,h))\n",
    "\n",
    "    # create complex\n",
    "    cmplx = gd.CubicalComplex(dimensions=(h, h), top_dimensional_cells=(sublevel*image))\n",
    "\n",
    "    # get pairs of critical simplices\n",
    "    cmplx.compute_persistence()\n",
    "    critical_pairs = cmplx.cofaces_of_persistence_pairs()\n",
    "    \n",
    "    # get essential critical pixel\n",
    "    bpx0_essential = critical_pairs[1][0][0] // h, critical_pairs[1][0][0] % h\n",
    "\n",
    "    # get critical pixels corresponding to critical simplices\n",
    "    try:\n",
    "        bpx0 = [critical_pairs[0][0][i][0] for i in range(len(critical_pairs[0][0]))]\n",
    "        dpx0 = [critical_pairs[0][0][i][1] for i in range(len(critical_pairs[0][0]))]\n",
    "    except IndexError:\n",
    "        bpx0 = []\n",
    "        dpx0 = []\n",
    "        \n",
    "    try:\n",
    "        bpx1 = [critical_pairs[0][1][i][0] for i in range(len(critical_pairs[0][1]))]\n",
    "        dpx1 = [critical_pairs[0][1][i][1] for i in range(len(critical_pairs[0][1]))]\n",
    "    except IndexError:\n",
    "        bpx1 = []\n",
    "        dpx1 = []\n",
    "    \n",
    "\n",
    "    flat_image = image_sq.flatten()\n",
    "    pd0_essential = torch.tensor([[image_sq[bpx0_essential], torch.max(image)]])\n",
    "\n",
    "    if (len(bpx0)!=0):\n",
    "        pdb0 = flat_image[bpx0][:, None]\n",
    "        pdd0 = flat_image[dpx0][:, None]\n",
    "        pd0 = torch.Tensor(torch.hstack([pdb0, pdd0]))\n",
    "        pd0 = torch.vstack([pd0, pd0_essential.to(device)])\n",
    "    else:\n",
    "        pd0 = pd0_essential\n",
    "\n",
    "    if (len(bpx1)!=0):\n",
    "        pdb1 = flat_image[bpx1][:, None]\n",
    "        pdd1 = flat_image[dpx1][:, None]\n",
    "        pd1 = torch.Tensor(torch.hstack([pdb1, pdd1]))\n",
    "    else:\n",
    "        pd1 = torch.zeros((1, 2))\n",
    "    \n",
    "    return pd0, pd1\n",
    "\n",
    "\n",
    "def process_by_direction(img, alpha):\n",
    "    X = (math.cos(alpha) - (np.arange(0, img.shape[0]) - (img.shape[0] / 2 - 0.5)) / (img.shape[0] * math.sqrt(2))) * math.cos(alpha) / 2\n",
    "    Y = (math.sin(alpha) - (np.arange(0, img.shape[1]) - (img.shape[1] / 2 - 0.5)) / (img.shape[1] * math.sqrt(2))) * math.sin(alpha) / 2\n",
    "    direction_filter = X.reshape(-1, 1) + Y.reshape(1, -1)\n",
    "    return np.maximum(direction_filter, img)\n",
    "\n",
    "\n",
    "def process_image(img, filter_params, device):\n",
    "    w = int(np.sqrt(img.flatten().shape[0]))\n",
    "    imgs = [process_by_direction(img.reshape(w, w), alpha) for alpha in filter_params]\n",
    "    diagrams = []\n",
    "    for i, img in enumerate(imgs):\n",
    "        res = diagram(torch.Tensor(img.flatten()), device=device)\n",
    "        for j in range(len(res)):\n",
    "            if not res[j].shape[0]:\n",
    "                diagrams.append(torch.zeros(0, 4))\n",
    "            else:\n",
    "                diagrams.append(torch.concatenate([res[j], torch.Tensor([[j, filter_params[i]] for _ in range(res[j].shape[0])])], axis=1))\n",
    "\n",
    "    diagrams = torch.concatenate(diagrams)\n",
    "    return diagrams\n",
    "\n",
    "\n",
    "def process_by_conv(img, conv, device):\n",
    "    w = int(np.sqrt(img.flatten().shape[0]))\n",
    "    img = conv(torch.Tensor(img).reshape(1, w, w)).detach()\n",
    "    diagrams = []\n",
    "    for i in range(img.shape[0]):\n",
    "        res = diagram(img[i].flatten(), device=device)\n",
    "        for j in range(len(res)):\n",
    "            if not res[j].shape[0]:\n",
    "                diagrams.append(torch.zeros(0, 4))\n",
    "            else:\n",
    "                diagrams.append(torch.concatenate([res[j], torch.Tensor([[j, i] for _ in range(res[j].shape[0])])], axis=1))\n",
    "    diagrams = torch.concatenate(diagrams)\n",
    "    return diagrams\n",
    "\n",
    "\n",
    "def process_baseline(img, device):\n",
    "    diagrams = []\n",
    "    res = diagram(torch.Tensor(img.flatten()), device=device)\n",
    "    for j in range(len(res)):\n",
    "        if not res[j].shape[0]:\n",
    "            diagrams.append(torch.zeros(0, 4))\n",
    "        else:\n",
    "            diagrams.append(torch.concatenate([res[j], torch.Tensor([[j, 1] for _ in range(res[j].shape[0])])], axis=1))\n",
    "    diagrams = torch.concatenate(diagrams)\n",
    "    return diagrams\n",
    "\n",
    "\n",
    "def process_cedt(img, device):\n",
    "    img /= img.max()\n",
    "    edt = torch.Tensor(distance_transform_edt(img > 0.5))\n",
    "    cedt = edt * (img > 0.5) - edt * (img <= 0.5)\n",
    "    return process_baseline(cedt, device=device)\n",
    "\n",
    "\n",
    "def process_cedt_thickening(img, window_size, device):\n",
    "    img /= img.max()\n",
    "    img = maximum_filter(img, size=window_size)\n",
    "    edt = torch.Tensor(distance_transform_edt(img > 0.5))\n",
    "    cedt = edt * (img > 0.5) - edt * (img <= 0.5)\n",
    "    return process_baseline(cedt, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 250\n",
    "S = 228\n",
    "image = generate(N, S, W=300, sigma1=4, sigma2=2, t=0.01, bins=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = image[:63, :63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagram(torch.Tensor(t).flatten(), device=\"cpu\")[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([118, 4])\n",
      "torch.Size([247, 4])\n",
      "torch.Size([59, 4])\n",
      "torch.Size([25, 4])\n",
      "torch.Size([18, 4])\n"
     ]
    }
   ],
   "source": [
    "# dir\n",
    "print(process_image(torch.Tensor(t).flatten(), [0, np.pi / 2], device=\"cpu\").shape)\n",
    "\n",
    "# conv\n",
    "conv = nn.Conv2d(1, 4, kernel_size=3)\n",
    "print(process_by_conv(torch.Tensor(t).flatten(), conv, device=\"cpu\").shape)\n",
    "\n",
    "# baseline\n",
    "print(process_baseline(torch.Tensor(t).flatten(), device=\"cpu\").shape)\n",
    "\n",
    "# cedt\n",
    "print(process_cedt(torch.Tensor(t).flatten(), device=\"cpu\").shape)\n",
    "\n",
    "# thickening cedt\n",
    "print(process_cedt_thickening(torch.Tensor(t).flatten(), 3, device=\"cpu\").shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
