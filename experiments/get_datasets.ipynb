{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rips(maxdim=1, thresh=inf, coeff=2, do_cocycles=False, n_perm = None, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "from datasets import *\n",
    "from transforms import *\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ripser import lower_star_img\n",
    "from ripser import Rips\n",
    "vr = Rips()\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "\n",
    "import persim\n",
    "import diagram2vec\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "from gtda.diagrams import PersistenceEntropy, PersistenceImage, BettiCurve\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 300\n",
    "sigma1 = 4\n",
    "sigma2 = 2\n",
    "t = 0.01\n",
    "\n",
    "def generate(N, S, W=300, sigma1=4, sigma2=2, t=0.01, bins=64):\n",
    "\n",
    "    z = np.zeros((N, S, 2))\n",
    "    for n in range(N):\n",
    "        z[n, 0] = np.random.uniform(0, W, size=(2))\n",
    "        for s in range(S-1):\n",
    "            d_1 = np.random.normal(0, sigma1)\n",
    "            d_2 = np.random.normal(0, sigma1)\n",
    "            z[n, s+1, 0] = (z[n, s, 0] + d_1) % W\n",
    "            z[n, s+1, 1] = (z[n, s, 1] + d_2) % W\n",
    "\n",
    "    z_r = z.reshape(N*S, 2)\n",
    "    H, _, _ = np.histogram2d(z_r[:,0], z_r[:,1], bins=bins)\n",
    "    \n",
    "    G = gaussian_filter(H, sigma2)\n",
    "    G[G < t] = 0\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:35<00:00, 280.81it/s]\n",
      "100%|██████████| 10000/10000 [00:29<00:00, 333.62it/s]\n"
     ]
    }
   ],
   "source": [
    "count = 10000\n",
    "classes_count = 2\n",
    "\n",
    "images = np.zeros((classes_count * count, 64, 64))\n",
    "\n",
    "# class A\n",
    "N = 100\n",
    "S = 30\n",
    "\n",
    "for n in tqdm(range(count)):\n",
    "    images[n] = generate(N, S)\n",
    "    \n",
    "# class B\n",
    "N = 250\n",
    "S = 10\n",
    "\n",
    "for n in tqdm(range(count)):\n",
    "    images[n+count] = generate(N, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_diagrams(diagrams, name):\n",
    "    labels = [0 for _ in range(count)] + [1 for _ in range(count)]\n",
    "    pairs = list(zip(diagrams, labels))\n",
    "\n",
    "    train_pairs, test_pairs = train_test_split(pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_diagrams, train_labels = zip(*train_pairs)\n",
    "    test_diagrams, test_labels = zip(*test_pairs)\n",
    "\n",
    "    train_dataset = DiagramsDataset(train_diagrams, train_labels)\n",
    "    test_dataset = DiagramsDataset(test_diagrams, test_labels)\n",
    "\n",
    "    torch.save(train_dataset, f\"../data/porus/{name}_train.pt\")\n",
    "    torch.save(test_dataset, f\"../data/porus/{name}_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:04<00:00, 161.23it/s]\n"
     ]
    }
   ],
   "source": [
    "baseline_diagrams = [\n",
    "    process_baseline(torch.Tensor(t).flatten(), device=\"cpu\") for t in tqdm(images)\n",
    "]\n",
    "push_diagrams(baseline_diagrams, \"baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:10<00:00, 153.14it/s]\n"
     ]
    }
   ],
   "source": [
    "cedt_diagrams = [\n",
    "    process_cedt(torch.Tensor(t).flatten(), device=\"cpu\") for t in tqdm(images)\n",
    "]\n",
    "push_diagrams(cedt_diagrams, \"cedt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:12<00:00, 150.99it/s]\n",
      "100%|██████████| 20000/20000 [02:12<00:00, 151.21it/s]\n",
      "100%|██████████| 20000/20000 [02:12<00:00, 150.83it/s]\n",
      "100%|██████████| 20000/20000 [02:13<00:00, 149.59it/s]\n",
      "100%|██████████| 20000/20000 [02:13<00:00, 150.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for thickening in [1, 2, 3, 5, 8]:\n",
    "    cedt_diagrams = [\n",
    "        process_cedt_thickening(torch.Tensor(t).flatten(), thickening, device=\"cpu\") for t in tqdm(images)\n",
    "    ]\n",
    "    push_diagrams(cedt_diagrams, f\"cedt_thickening_{thickening}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:06<00:00, 157.72it/s]\n",
      "100%|██████████| 20000/20000 [08:25<00:00, 39.58it/s]\n",
      "100%|██████████| 20000/20000 [20:49<00:00, 16.00it/s]\n"
     ]
    }
   ],
   "source": [
    "for dir_count in [1, 4, 10]:\n",
    "    dirs = np.arange(dir_count) / dir_count * 2 * np.pi\n",
    "    cedt_diagrams = [\n",
    "        process_image(torch.Tensor(t).flatten(), dirs, device=\"cpu\") for t in tqdm(images)\n",
    "    ]\n",
    "    push_diagrams(cedt_diagrams, f\"directional_{dir_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:05<00:00, 159.43it/s]\n",
      "100%|██████████| 20000/20000 [08:35<00:00, 38.82it/s]\n",
      "100%|██████████| 20000/20000 [20:44<00:00, 16.06it/s]\n"
     ]
    }
   ],
   "source": [
    "for conv_count in [1, 4, 10]:\n",
    "    conv = nn.Conv2d(1, conv_count, kernel_size=3)\n",
    "    cedt_diagrams = [\n",
    "        process_by_conv(torch.Tensor(t).flatten(), conv, device=\"cpu\") for t in tqdm(images)\n",
    "    ]\n",
    "    push_diagrams(cedt_diagrams, f\"convolution_{conv_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0 for _ in range(count)] + [1 for _ in range(count)]\n",
    "pairs = list(zip(images, labels))\n",
    "\n",
    "train_pairs, test_pairs = train_test_split(pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "train_images, train_labels = zip(*train_pairs)\n",
    "test_images, test_labels = zip(*test_pairs)\n",
    "\n",
    "train_dataset = ImagesDataset(train_images, train_labels)\n",
    "test_dataset = ImagesDataset(test_images, test_labels)\n",
    "\n",
    "torch.save(train_dataset, f\"../data/porus/images_train.pt\")\n",
    "torch.save(test_dataset, f\"../data/porus/images_test.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "mnist_train = torchvision.datasets.MNIST('../data/mnist/base_mnist_train_data', train=True, download=True, transform=transform)\n",
    "mnist_test = torchvision.datasets.MNIST('../data/mnist/base_mnist_test_data', train=False, download=True, transform=transform)\n",
    "X_train = mnist_train.data.numpy() / 255\n",
    "X_test = mnist_test.data.numpy() / 255\n",
    "y_train = mnist_train.targets.numpy()\n",
    "y_test = mnist_test.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_diagrams_mnist(train_diagrams, test_diagrams, train_labels, test_labels, name):\n",
    "    train_dataset = DiagramsDataset(train_diagrams, train_labels)\n",
    "    test_dataset = DiagramsDataset(test_diagrams, test_labels)\n",
    "\n",
    "    torch.save(train_dataset, f\"../data/mnist/{name}_train.pt\")\n",
    "    torch.save(test_dataset, f\"../data/mnist/{name}_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:14<00:00, 806.87it/s]\n",
      "100%|██████████| 10000/10000 [00:12<00:00, 802.34it/s]\n"
     ]
    }
   ],
   "source": [
    "train_diagrams = [\n",
    "    process_baseline(torch.Tensor(t).flatten(), device=\"cpu\") for t in tqdm(X_train)\n",
    "]\n",
    "test_diagrams = [\n",
    "    process_baseline(torch.Tensor(t).flatten(), device=\"cpu\") for t in tqdm(X_test)\n",
    "]\n",
    "push_diagrams_mnist(train_diagrams, test_diagrams, y_train, y_test, \"baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:17<00:00, 778.39it/s]\n",
      "100%|██████████| 10000/10000 [00:12<00:00, 776.57it/s]\n"
     ]
    }
   ],
   "source": [
    "train_diagrams = [\n",
    "    process_cedt(torch.Tensor(t).flatten(), device=\"cpu\") for t in tqdm(X_train)\n",
    "]\n",
    "test_diagrams = [\n",
    "    process_cedt(torch.Tensor(t).flatten(), device=\"cpu\") for t in tqdm(X_test)\n",
    "]\n",
    "push_diagrams_mnist(train_diagrams, test_diagrams, y_train, y_test, \"cedt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:19<00:00, 755.49it/s]\n",
      "100%|██████████| 10000/10000 [00:13<00:00, 768.50it/s]\n",
      "100%|██████████| 60000/60000 [01:19<00:00, 750.52it/s]\n",
      "100%|██████████| 10000/10000 [00:13<00:00, 743.57it/s]\n",
      "100%|██████████| 60000/60000 [01:20<00:00, 747.35it/s]\n",
      "100%|██████████| 10000/10000 [00:13<00:00, 742.49it/s]\n",
      "100%|██████████| 60000/60000 [01:21<00:00, 738.02it/s]\n",
      "100%|██████████| 10000/10000 [00:13<00:00, 741.49it/s]\n",
      "100%|██████████| 60000/60000 [01:20<00:00, 745.55it/s]\n",
      "100%|██████████| 10000/10000 [00:13<00:00, 727.36it/s]\n"
     ]
    }
   ],
   "source": [
    "for thickening in [1, 2, 3, 5, 8]:\n",
    "    train_diagrams = [\n",
    "        process_cedt_thickening(torch.Tensor(t).flatten(), thickening, device=\"cpu\") for t in tqdm(X_train)\n",
    "    ]\n",
    "    test_diagrams = [\n",
    "        process_cedt_thickening(torch.Tensor(t).flatten(), thickening, device=\"cpu\") for t in tqdm(X_test)\n",
    "    ]\n",
    "    push_diagrams_mnist(train_diagrams, test_diagrams, y_train, y_test, f\"cedt_thickening_{thickening}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:14<00:00, 808.48it/s]\n",
      "100%|██████████| 10000/10000 [00:12<00:00, 824.59it/s]\n",
      "100%|██████████| 60000/60000 [04:59<00:00, 200.21it/s]\n",
      "100%|██████████| 10000/10000 [00:51<00:00, 195.57it/s]\n",
      "100%|██████████| 60000/60000 [12:04<00:00, 82.84it/s]\n",
      "100%|██████████| 10000/10000 [02:00<00:00, 82.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for dir_count in [1, 4, 10]:\n",
    "    dirs = np.arange(dir_count) / dir_count * 2 * np.pi\n",
    "    train_diagrams = [\n",
    "        process_image(torch.Tensor(t).flatten(), dirs, device=\"cpu\") for t in tqdm(X_train)\n",
    "    ]\n",
    "    test_diagrams = [\n",
    "        process_image(torch.Tensor(t).flatten(), dirs, device=\"cpu\") for t in tqdm(X_test)\n",
    "    ]\n",
    "    push_diagrams_mnist(train_diagrams, test_diagrams, y_train, y_test, f\"directional_{dir_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:10<00:00, 854.89it/s]\n",
      "100%|██████████| 10000/10000 [00:11<00:00, 841.26it/s]\n",
      "100%|██████████| 60000/60000 [04:38<00:00, 215.40it/s]\n",
      "100%|██████████| 10000/10000 [00:48<00:00, 208.14it/s]\n",
      "100%|██████████| 60000/60000 [11:40<00:00, 85.62it/s]\n",
      "100%|██████████| 10000/10000 [01:58<00:00, 84.70it/s]\n"
     ]
    }
   ],
   "source": [
    "for conv_count in [1, 4, 10]:\n",
    "    torch.random.manual_seed(42)\n",
    "    conv = nn.Conv2d(1, conv_count, kernel_size=3)\n",
    "    train_diagrams = [\n",
    "        process_by_conv(torch.Tensor(t).flatten(), conv, device=\"cpu\") for t in tqdm(X_train)\n",
    "    ]\n",
    "    test_diagrams = [\n",
    "        process_by_conv(torch.Tensor(t).flatten(), conv, device=\"cpu\") for t in tqdm(X_test)\n",
    "    ]\n",
    "    push_diagrams_mnist(train_diagrams, test_diagrams, y_train, y_test, f\"convolution_{conv_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImagesDataset(X_train, y_train)\n",
    "test_dataset = ImagesDataset(X_test, y_test)\n",
    "\n",
    "torch.save(train_dataset, f\"../data/mnist/images_train.pt\")\n",
    "torch.save(test_dataset, f\"../data/mnist/images_test.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "cifar_train = torchvision.datasets.CIFAR10('../data/cifar10/base_cifar10_train_data', train=True, download=True, transform=transform)\n",
    "cifar_test = torchvision.datasets.CIFAR10('../data/cifar10/base_cifar10_test_data', train=False, download=True, transform=transform)\n",
    "X_train = cifar_train.data / 255\n",
    "X_test = cifar_test.data / 255\n",
    "y_train = np.array(cifar_train.targets)\n",
    "y_test = np.array(cifar_test.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average on last channel\n",
    "X_train = np.mean(X_train, axis=-1)\n",
    "X_test = np.mean(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_diagrams_cifar(train_diagrams, test_diagrams, train_labels, test_labels, name):\n",
    "    train_dataset = DiagramsDataset(train_diagrams, train_labels)\n",
    "    test_dataset = DiagramsDataset(test_diagrams, test_labels)\n",
    "\n",
    "    torch.save(train_dataset, f\"../data/cifar10/{name}_train.pt\")\n",
    "    torch.save(test_dataset, f\"../data/cifar10/{name}_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [01:29<00:00, 558.49it/s]\n",
      "100%|██████████| 10000/10000 [00:17<00:00, 558.13it/s]\n"
     ]
    }
   ],
   "source": [
    "train_diagrams = [\n",
    "    process_baseline(torch.Tensor(t).flatten(), device=\"cpu\") for t in tqdm(X_train)\n",
    "]\n",
    "test_diagrams = [\n",
    "    process_baseline(torch.Tensor(t).flatten(), device=\"cpu\") for t in tqdm(X_test)\n",
    "]\n",
    "push_diagrams_cifar(train_diagrams, test_diagrams, y_train, y_test, \"baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [01:26<00:00, 578.34it/s]\n",
      "100%|██████████| 10000/10000 [00:16<00:00, 611.02it/s]\n"
     ]
    }
   ],
   "source": [
    "train_diagrams = [\n",
    "    process_cedt(torch.Tensor(t).flatten(), device=\"cpu\") for t in tqdm(X_train)\n",
    "]\n",
    "test_diagrams = [\n",
    "    process_cedt(torch.Tensor(t).flatten(), device=\"cpu\") for t in tqdm(X_test)\n",
    "]\n",
    "push_diagrams_cifar(train_diagrams, test_diagrams, y_train, y_test, \"cedt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [01:28<00:00, 566.49it/s]\n",
      "100%|██████████| 10000/10000 [00:17<00:00, 561.19it/s]\n",
      "100%|██████████| 50000/50000 [01:26<00:00, 580.78it/s]\n",
      "100%|██████████| 10000/10000 [00:17<00:00, 581.21it/s]\n",
      "100%|██████████| 50000/50000 [01:25<00:00, 582.27it/s]\n",
      "100%|██████████| 10000/10000 [00:16<00:00, 589.99it/s]\n",
      "100%|██████████| 50000/50000 [01:26<00:00, 579.47it/s]\n",
      "100%|██████████| 10000/10000 [00:16<00:00, 597.38it/s]\n",
      "100%|██████████| 50000/50000 [01:23<00:00, 599.88it/s]\n",
      "100%|██████████| 10000/10000 [00:16<00:00, 595.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for thickening in [1, 2, 3, 5, 8]:\n",
    "    train_diagrams = [\n",
    "        process_cedt_thickening(torch.Tensor(t).flatten(), thickening, device=\"cpu\") for t in tqdm(X_train)\n",
    "    ]\n",
    "    test_diagrams = [\n",
    "        process_cedt_thickening(torch.Tensor(t).flatten(), thickening, device=\"cpu\") for t in tqdm(X_test)\n",
    "    ]\n",
    "    push_diagrams_cifar(train_diagrams, test_diagrams, y_train, y_test, f\"cedt_thickening_{thickening}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [01:27<00:00, 570.15it/s]\n",
      "100%|██████████| 10000/10000 [00:17<00:00, 563.01it/s]\n",
      "100%|██████████| 50000/50000 [05:49<00:00, 143.04it/s]\n",
      "100%|██████████| 10000/10000 [01:09<00:00, 144.65it/s]\n",
      "100%|██████████| 50000/50000 [14:06<00:00, 59.10it/s]\n",
      "100%|██████████| 10000/10000 [02:48<00:00, 59.35it/s]\n"
     ]
    }
   ],
   "source": [
    "for dir_count in [1, 4, 10]:\n",
    "    dirs = np.arange(dir_count) / dir_count * 2 * np.pi\n",
    "    train_diagrams = [\n",
    "        process_image(torch.Tensor(t).flatten(), dirs, device=\"cpu\") for t in tqdm(X_train)\n",
    "    ]\n",
    "    test_diagrams = [\n",
    "        process_image(torch.Tensor(t).flatten(), dirs, device=\"cpu\") for t in tqdm(X_test)\n",
    "    ]\n",
    "    push_diagrams_cifar(train_diagrams, test_diagrams, y_train, y_test, f\"directional_{dir_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [01:17<00:00, 647.26it/s]\n",
      "100%|██████████| 10000/10000 [00:15<00:00, 649.17it/s]\n",
      "100%|██████████| 50000/50000 [05:15<00:00, 158.66it/s]\n",
      "100%|██████████| 10000/10000 [01:01<00:00, 161.44it/s]\n",
      "100%|██████████| 50000/50000 [13:24<00:00, 62.13it/s]\n",
      "100%|██████████| 10000/10000 [02:45<00:00, 60.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for conv_count in [1, 4, 10]:\n",
    "    torch.random.manual_seed(42)\n",
    "    conv = nn.Conv2d(1, conv_count, kernel_size=3)\n",
    "    train_diagrams = [\n",
    "        process_by_conv(torch.Tensor(t).flatten(), conv, device=\"cpu\") for t in tqdm(X_train)\n",
    "    ]\n",
    "    test_diagrams = [\n",
    "        process_by_conv(torch.Tensor(t).flatten(), conv, device=\"cpu\") for t in tqdm(X_test)\n",
    "    ]\n",
    "    push_diagrams_cifar(train_diagrams, test_diagrams, y_train, y_test, f\"convolution_{conv_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImagesDataset(X_train, y_train)\n",
    "test_dataset = ImagesDataset(X_test, y_test)\n",
    "\n",
    "torch.save(train_dataset, f\"../data/cifar10/images_train.pt\")\n",
    "torch.save(test_dataset, f\"../data/cifar10/images_test.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chinese MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/chinese-mnist/chinese_mnist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {value: i for i, value in enumerate(sorted(df.value.unique()))}\n",
    "\n",
    "def get_sample(row):\n",
    "    path = os.path.join('../data/chinese-mnist/data/data', f'input_{row.suite_id}_{row.sample_id}_{row.code}.jpg')\n",
    "    image = Image.open(path)\n",
    "    image = np.array(image) / 255\n",
    "    label = label_mapping[row.value]\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_diagrams_chinese_mnist(train_diagrams, test_diagrams, train_labels, test_labels, name):\n",
    "    train_dataset = DiagramsDataset(train_diagrams, train_labels)\n",
    "    test_dataset = DiagramsDataset(test_diagrams, test_labels)\n",
    "\n",
    "    torch.save(train_dataset, f\"../data/chinese-mnist/{name}_train.pt\")\n",
    "    torch.save(test_dataset, f\"../data/chinese-mnist/{name}_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [get_sample(row) for _, row in df.iterrows()]\n",
    "train_pairs, test_pairs = train_test_split(pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, y_train = zip(*train_pairs)\n",
    "X_test, y_test = zip(*test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [01:18<00:00, 153.81it/s]\n",
      "100%|██████████| 3000/3000 [00:19<00:00, 150.12it/s]\n"
     ]
    }
   ],
   "source": [
    "train_diagrams = [\n",
    "    process_baseline(torch.Tensor(t).flatten(), device=\"cpu\") for t in tqdm(X_train)\n",
    "]\n",
    "test_diagrams = [\n",
    "    process_baseline(torch.Tensor(t).flatten(), device=\"cpu\") for t in tqdm(X_test)\n",
    "]\n",
    "push_diagrams_chinese_mnist(train_diagrams, test_diagrams, y_train, y_test, \"baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [01:10<00:00, 171.24it/s]\n",
      "100%|██████████| 3000/3000 [00:17<00:00, 167.32it/s]\n"
     ]
    }
   ],
   "source": [
    "train_diagrams = [\n",
    "    process_cedt(torch.Tensor(t).flatten(), device=\"cpu\") for t in tqdm(X_train)\n",
    "]\n",
    "test_diagrams = [\n",
    "    process_cedt(torch.Tensor(t).flatten(), device=\"cpu\") for t in tqdm(X_test)\n",
    "]\n",
    "push_diagrams_chinese_mnist(train_diagrams, test_diagrams, y_train, y_test, \"cedt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [01:11<00:00, 167.18it/s]\n",
      "100%|██████████| 3000/3000 [00:18<00:00, 166.64it/s]\n",
      "100%|██████████| 12000/12000 [01:12<00:00, 166.41it/s]\n",
      "100%|██████████| 3000/3000 [00:18<00:00, 161.60it/s]\n",
      "100%|██████████| 12000/12000 [01:13<00:00, 163.31it/s]\n",
      "100%|██████████| 3000/3000 [00:18<00:00, 164.42it/s]\n",
      "100%|██████████| 12000/12000 [01:12<00:00, 164.89it/s]\n",
      "100%|██████████| 3000/3000 [00:18<00:00, 160.54it/s]\n",
      "100%|██████████| 12000/12000 [01:13<00:00, 163.55it/s]\n",
      "100%|██████████| 3000/3000 [00:18<00:00, 163.14it/s]\n"
     ]
    }
   ],
   "source": [
    "for thickening in [1, 2, 3, 5, 8]:\n",
    "    train_diagrams = [\n",
    "        process_cedt_thickening(torch.Tensor(t).flatten(), thickening, device=\"cpu\") for t in tqdm(X_train)\n",
    "    ]\n",
    "    test_diagrams = [\n",
    "        process_cedt_thickening(torch.Tensor(t).flatten(), thickening, device=\"cpu\") for t in tqdm(X_test)\n",
    "    ]\n",
    "    push_diagrams_chinese_mnist(train_diagrams, test_diagrams, y_train, y_test, f\"cedt_thickening_{thickening}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [01:12<00:00, 165.59it/s]\n",
      "100%|██████████| 3000/3000 [00:17<00:00, 168.98it/s]\n",
      "100%|██████████| 12000/12000 [04:51<00:00, 41.17it/s]\n",
      "100%|██████████| 3000/3000 [01:13<00:00, 40.81it/s]\n",
      "100%|██████████| 12000/12000 [12:09<00:00, 16.46it/s] \n",
      "100%|██████████| 3000/3000 [02:59<00:00, 16.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for dir_count in [1, 4, 10]:\n",
    "    dirs = np.arange(dir_count) / dir_count * 2 * np.pi\n",
    "    train_diagrams = [\n",
    "        process_image(torch.Tensor(t).flatten(), dirs, device=\"cpu\") for t in tqdm(X_train)\n",
    "    ]\n",
    "    test_diagrams = [\n",
    "        process_image(torch.Tensor(t).flatten(), dirs, device=\"cpu\") for t in tqdm(X_test)\n",
    "    ]\n",
    "    push_diagrams_chinese_mnist(train_diagrams, test_diagrams, y_train, y_test, f\"directional_{dir_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [01:24<00:00, 142.41it/s]\n",
      "100%|██████████| 3000/3000 [00:22<00:00, 135.28it/s]\n",
      "100%|██████████| 12000/12000 [05:26<00:00, 36.70it/s]\n",
      "100%|██████████| 3000/3000 [01:23<00:00, 36.04it/s]\n",
      "100%|██████████| 12000/12000 [13:45<00:00, 14.53it/s] \n",
      "100%|██████████| 3000/3000 [03:23<00:00, 14.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for conv_count in [1, 4, 10]:\n",
    "    torch.random.manual_seed(42)\n",
    "    conv = nn.Conv2d(1, conv_count, kernel_size=3)\n",
    "    train_diagrams = [\n",
    "        process_by_conv(torch.Tensor(t).flatten(), conv, device=\"cpu\") for t in tqdm(X_train)\n",
    "    ]\n",
    "    test_diagrams = [\n",
    "        process_by_conv(torch.Tensor(t).flatten(), conv, device=\"cpu\") for t in tqdm(X_test)\n",
    "    ]\n",
    "    push_diagrams_chinese_mnist(train_diagrams, test_diagrams, y_train, y_test, f\"convolution_{conv_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImagesDataset(X_train, y_train)\n",
    "test_dataset = ImagesDataset(X_test, y_test)\n",
    "\n",
    "torch.save(train_dataset, f\"../data/chinese-mnist/images_train.pt\")\n",
    "torch.save(test_dataset, f\"../data/chinese-mnist/images_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
